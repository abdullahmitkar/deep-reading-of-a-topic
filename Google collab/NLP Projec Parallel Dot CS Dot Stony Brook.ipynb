{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP Projec Parallel.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3Eb5p_JDOQZN","colab_type":"code","colab":{}},"source":["# # For More RAM\n","# def function(l):\n","#     l.append([0]*500000000)\n","#     return l\n","\n","# l=[]\n","# while True:\n","#   l=function(l)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ToqUXI6PMHl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"aaa2a60d-6de6-403c-de25-5c62fafd969a","executionInfo":{"status":"ok","timestamp":1576022100092,"user_tz":300,"elapsed":382,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}}},"source":["pwd"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"2ydVplOiOXKO","colab_type":"code","outputId":"c7e4202d-173d-439b-a0e2-ac18047a5fee","executionInfo":{"status":"ok","timestamp":1576022123783,"user_tz":300,"elapsed":19721,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["# Mount your google drive where you've saved your assignment folder\n","import torch\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rTp2J1llOnB-","colab_type":"code","outputId":"3d877554-7b98-4046-9cbe-f79b147f44e3","executionInfo":{"status":"ok","timestamp":1576022141951,"user_tz":300,"elapsed":367,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd '/content/gdrive/My Drive/Project/transformers'\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Project/transformers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aTk63FrokNAt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":546},"outputId":"f367b123-7ea6-4392-8540-caab385b3272","executionInfo":{"status":"ok","timestamp":1576022160483,"user_tz":300,"elapsed":17505,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}}},"source":["pip install pytorch-pretrained-bert"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n","\u001b[K     |████████████████████████████████| 675kB 44.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n","Building wheels for collected packages: regex\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609184 sha256=384733d23187e3bfd1a214f87420c650c9dce95cbf7140246ea3936e072aae13\n","  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n","Successfully built regex\n","Installing collected packages: regex, pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nIgwsPvTO7aT","colab_type":"code","outputId":"77f771c1-d54d-4957-925a-0cbecf7f9708","executionInfo":{"status":"ok","timestamp":1576022224306,"user_tz":300,"elapsed":31871,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install -r requirements.txt\n","!python setup.py build\n","!python setup.py install"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.10.32)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2.21.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2019.12.9)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 34.8MB/s \n","\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->-r requirements.txt (line 4)) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->-r requirements.txt (line 4)) (0.9.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->-r requirements.txt (line 4)) (1.13.32)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 6)) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 6)) (2019.11.28)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 12)) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 12)) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 12)) (0.14.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->-r requirements.txt (line 4)) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->-r requirements.txt (line 4)) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d1a24e4f85240cd480e67ab4521b2ec080a987d8065074454de76b239cb9cd9b\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses\n","Successfully installed sacremoses-0.0.35 sentencepiece-0.1.83\n","running build\n","running build_py\n","running build_scripts\n","changing mode of build/scripts-3.6/transformers-cli from 600 to 755\n","running install\n","running bdist_egg\n","running egg_info\n","writing transformers.egg-info/PKG-INFO\n","writing dependency_links to transformers.egg-info/dependency_links.txt\n","writing entry points to transformers.egg-info/entry_points.txt\n","writing requirements to transformers.egg-info/requires.txt\n","writing top-level names to transformers.egg-info/top_level.txt\n","reading manifest template 'MANIFEST.in'\n","writing manifest file 'transformers.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_camembert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_auto.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_gpt2.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_pytorch_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_distilbert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_transfo_xl_utilities.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_auto.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_transfo_xl_utilities.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_ctrl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_roberta.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_transfo_xl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_beam_search.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_bert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/hf_api.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_albert_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_transfo_xl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_transfo_xl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_xlm.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_ctrl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_xlnet.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_openai.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/optimization_tf.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_xlnet.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_bert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_encoder_decoder.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_openai.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_camembert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_distilbert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_roberta.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_gpt2.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_albert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_roberta.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_albert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_openai.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_auto.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_albert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/__init__.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_bert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_xlnet.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_xlm.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/optimization.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_distilbert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/file_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_pytorch_checkpoint_to_tf2.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_xlm.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/__main__.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_gpt2.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/modeling_tf_ctrl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/configuration_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_utils.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_auto.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_transfo_xl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_xlnet.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_bert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_ctrl.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_openai.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_gpt2.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_distilbert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_camembert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_xlm.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_albert.py -> build/bdist.linux-x86_64/egg/transformers\n","copying build/lib/transformers/tokenization_roberta.py -> build/bdist.linux-x86_64/egg/transformers\n","creating build/bdist.linux-x86_64/egg/transformers/commands\n","copying build/lib/transformers/commands/user.py -> build/bdist.linux-x86_64/egg/transformers/commands\n","copying build/lib/transformers/commands/__init__.py -> build/bdist.linux-x86_64/egg/transformers/commands\n","creating build/bdist.linux-x86_64/egg/transformers/data\n","copying build/lib/transformers/data/__init__.py -> build/bdist.linux-x86_64/egg/transformers/data\n","creating build/bdist.linux-x86_64/egg/transformers/data/metrics\n","copying build/lib/transformers/data/metrics/__init__.py -> build/bdist.linux-x86_64/egg/transformers/data/metrics\n","creating build/bdist.linux-x86_64/egg/transformers/data/processors\n","copying build/lib/transformers/data/processors/utils.py -> build/bdist.linux-x86_64/egg/transformers/data/processors\n","copying build/lib/transformers/data/processors/xnli.py -> build/bdist.linux-x86_64/egg/transformers/data/processors\n","copying build/lib/transformers/data/processors/glue.py -> build/bdist.linux-x86_64/egg/transformers/data/processors\n","copying build/lib/transformers/data/processors/__init__.py -> build/bdist.linux-x86_64/egg/transformers/data/processors\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_camembert.py to modeling_camembert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_auto.py to modeling_auto.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_gpt2.py to modeling_gpt2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_pytorch_utils.py to modeling_tf_pytorch_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_distilbert.py to configuration_distilbert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_transfo_xl_utilities.py to modeling_transfo_xl_utilities.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_auto.py to modeling_tf_auto.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_transfo_xl_utilities.py to modeling_tf_transfo_xl_utilities.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_ctrl.py to configuration_ctrl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_roberta.py to configuration_roberta.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_transfo_xl.py to modeling_transfo_xl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_beam_search.py to modeling_beam_search.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_bert.py to configuration_bert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/hf_api.py to hf_api.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_albert_original_tf_checkpoint_to_pytorch.py to convert_albert_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_transfo_xl.py to modeling_tf_transfo_xl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_transfo_xl.py to configuration_transfo_xl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_utils.py to modeling_tf_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_xlm.py to modeling_tf_xlm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_ctrl.py to modeling_ctrl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py to convert_gpt2_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_xlnet.py to modeling_xlnet.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_openai.py to modeling_tf_openai.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/optimization_tf.py to optimization_tf.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_xlnet.py to configuration_xlnet.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_bert.py to modeling_bert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_encoder_decoder.py to modeling_encoder_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_openai.py to configuration_openai.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_camembert.py to configuration_camembert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_distilbert.py to modeling_tf_distilbert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_roberta.py to modeling_tf_roberta.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py to convert_xlm_original_pytorch_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_gpt2.py to configuration_gpt2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_albert.py to modeling_albert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py to convert_bert_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_roberta.py to modeling_roberta.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py to convert_roberta_original_pytorch_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_albert.py to configuration_albert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_openai.py to modeling_openai.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_auto.py to configuration_auto.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py to convert_bert_pytorch_checkpoint_to_original_tf.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_albert.py to modeling_tf_albert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_bert.py to modeling_tf_bert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_xlnet.py to modeling_tf_xlnet.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py to convert_xlnet_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_xlm.py to modeling_xlm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/optimization.py to optimization.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_distilbert.py to modeling_distilbert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/file_utils.py to file_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_pytorch_checkpoint_to_tf2.py to convert_pytorch_checkpoint_to_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_utils.py to modeling_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py to convert_transfo_xl_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_xlm.py to configuration_xlm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/__main__.py to __main__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_gpt2.py to modeling_tf_gpt2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py to convert_openai_original_tf_checkpoint_to_pytorch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/modeling_tf_ctrl.py to modeling_tf_ctrl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/configuration_utils.py to configuration_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_utils.py to tokenization_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_auto.py to tokenization_auto.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_transfo_xl.py to tokenization_transfo_xl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_xlnet.py to tokenization_xlnet.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_bert.py to tokenization_bert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_ctrl.py to tokenization_ctrl.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_openai.py to tokenization_openai.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_gpt2.py to tokenization_gpt2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_distilbert.py to tokenization_distilbert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_camembert.py to tokenization_camembert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_xlm.py to tokenization_xlm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_albert.py to tokenization_albert.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/tokenization_roberta.py to tokenization_roberta.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/commands/user.py to user.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/commands/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/metrics/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/processors/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/processors/xnli.py to xnli.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/processors/glue.py to glue.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/transformers/data/processors/__init__.py to __init__.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","running install_scripts\n","running build_scripts\n","changing mode of build/scripts-3.6/transformers-cli from 700 to 755\n","creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","copying build/scripts-3.6/transformers-cli -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/transformers-cli to 755\n","copying transformers.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying transformers.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying transformers.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying transformers.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying transformers.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying transformers.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/transformers-2.2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing transformers-2.2.1-py3.6.egg\n","Copying transformers-2.2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding transformers 2.2.1 to easy-install.pth file\n","Installing transformers-cli script to /usr/local/bin\n","Installing transformers script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.6/dist-packages/transformers-2.2.1-py3.6.egg\n","Processing dependencies for transformers==2.2.1\n","Searching for sacremoses==0.0.35\n","Best match: sacremoses 0.0.35\n","Adding sacremoses 0.0.35 to easy-install.pth file\n","Installing sacremoses script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for sentencepiece==0.1.83\n","Best match: sentencepiece 0.1.83\n","Adding sentencepiece 0.1.83 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for regex==2019.12.9\n","Best match: regex 2019.12.9\n","Adding regex 2019.12.9 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for tqdm==4.28.1\n","Best match: tqdm 4.28.1\n","Adding tqdm 4.28.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for requests==2.21.0\n","Best match: requests 2.21.0\n","Adding requests 2.21.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for boto3==1.10.32\n","Best match: boto3 1.10.32\n","Adding boto3 1.10.32 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.17.4\n","Best match: numpy 1.17.4\n","Adding numpy 1.17.4 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.12.0\n","Best match: six 1.12.0\n","Adding six 1.12.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for joblib==0.14.0\n","Best match: joblib 0.14.0\n","Adding joblib 0.14.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Click==7.0\n","Best match: Click 7.0\n","Adding Click 7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for chardet==3.0.4\n","Best match: chardet 3.0.4\n","Adding chardet 3.0.4 to easy-install.pth file\n","Installing chardetect script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for certifi==2019.11.28\n","Best match: certifi 2019.11.28\n","Adding certifi 2019.11.28 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for idna==2.8\n","Best match: idna 2.8\n","Adding idna 2.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for jmespath==0.9.4\n","Best match: jmespath 0.9.4\n","Adding jmespath 0.9.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for s3transfer==0.2.1\n","Best match: s3transfer 0.2.1\n","Adding s3transfer 0.2.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for botocore==1.13.32\n","Best match: botocore 1.13.32\n","Adding botocore 1.13.32 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.6.1\n","Best match: python-dateutil 2.6.1\n","Adding python-dateutil 2.6.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for docutils==0.15.2\n","Best match: docutils 0.15.2\n","Adding docutils 0.15.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for transformers==2.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_NK__RKEPLKK","colab_type":"code","outputId":"2bde1b36-dfc3-4f5a-af1b-900bb6dc8d18","executionInfo":{"status":"ok","timestamp":1576022831838,"user_tz":300,"elapsed":269991,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python examples/run_lm_finetuning.py --num_train_epochs=100 --output_dir=bert_base_qa_oxygen --overwrite_output_dir --model_type=bert     --model_name_or_path=bert_base_cased_qa  --do_train   --train_data_file=data/Oxygen.txt --mlm"],"execution_count":9,"outputs":[{"output_type":"stream","text":["12/11/2019 00:02:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","12/11/2019 00:02:45 - INFO - transformers.configuration_utils -   loading configuration file bert_base_cased_qa/config.json\n","12/11/2019 00:02:45 - INFO - transformers.configuration_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 28996\n","}\n","\n","12/11/2019 00:02:45 - INFO - transformers.tokenization_utils -   Model name 'bert_base_cased_qa' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'bert_base_cased_qa' is a path or url to a directory containing tokenizer files.\n","12/11/2019 00:02:45 - INFO - transformers.tokenization_utils -   loading file bert_base_cased_qa/vocab.txt\n","12/11/2019 00:02:45 - INFO - transformers.tokenization_utils -   loading file bert_base_cased_qa/added_tokens.json\n","12/11/2019 00:02:45 - INFO - transformers.tokenization_utils -   loading file bert_base_cased_qa/special_tokens_map.json\n","12/11/2019 00:02:45 - INFO - transformers.tokenization_utils -   loading file bert_base_cased_qa/tokenizer_config.json\n","12/11/2019 00:02:45 - INFO - transformers.modeling_utils -   loading weights file bert_base_cased_qa/pytorch_model.bin\n","12/11/2019 00:02:48 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","12/11/2019 00:02:48 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['qa_outputs.weight', 'qa_outputs.bias']\n","12/11/2019 00:02:52 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=510, cache_dir='', config_name='', device=device(type='cuda'), do_eval=False, do_lower_case=False, do_train=True, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert_base_cased_qa', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=100.0, output_dir='bert_base_qa_oxygen', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=50, save_total_limit=None, seed=42, server_ip='', server_port='', tokenizer_name='', train_data_file='data/Oxygen.txt', warmup_steps=0, weight_decay=0.0)\n","12/11/2019 00:02:52 - INFO - __main__ -   Loading features from cached file data/bert_base_cased_qa_cached_lm_510_Oxygen.txt\n","12/11/2019 00:02:52 - INFO - __main__ -   ***** Running training *****\n","12/11/2019 00:02:52 - INFO - __main__ -     Num examples = 27\n","12/11/2019 00:02:52 - INFO - __main__ -     Num Epochs = 100\n","12/11/2019 00:02:52 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","12/11/2019 00:02:52 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","12/11/2019 00:02:52 - INFO - __main__ -     Gradient Accumulation steps = 1\n","12/11/2019 00:02:52 - INFO - __main__ -     Total optimization steps = 700\n","Epoch:   0% 0/100 [00:00<?, ?it/s]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.82it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.85it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.91it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.12it/s]\u001b[A\n","Epoch:   1% 1/100 [00:02<03:50,  2.33s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  3.00it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.16it/s]\u001b[A\n","Epoch:   2% 2/100 [00:04<03:46,  2.31s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.85it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.89it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.12it/s]\u001b[A\n","Epoch:   3% 3/100 [00:06<03:44,  2.32s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.02it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  3.00it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  3.00it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.99it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:   4% 4/100 [00:09<03:41,  2.31s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.10it/s]\u001b[A\n","Epoch:   5% 5/100 [00:11<03:39,  2.31s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.01it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.88it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:   6% 6/100 [00:13<03:38,  2.32s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.91it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.06it/s]\u001b[A\n","Epoch:   7% 7/100 [00:16<03:36,  2.33s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A12/11/2019 00:03:08 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-50/config.json\n","12/11/2019 00:03:10 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-50/pytorch_model.bin\n","12/11/2019 00:03:10 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-50\n","\n","Iteration:  14% 1/7 [00:01<00:11,  1.85s/it]\u001b[A\n","Iteration:  29% 2/7 [00:02<00:06,  1.40s/it]\u001b[A\n","Iteration:  43% 3/7 [00:02<00:04,  1.08s/it]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:02,  1.16it/s]\u001b[A\n","Iteration:  71% 5/7 [00:03<00:01,  1.41it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.66it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  1.99it/s]\u001b[A\n","Epoch:   8% 8/100 [00:20<04:16,  2.79s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.77it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.79it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.88it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:   9% 9/100 [00:22<04:02,  2.66s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.93it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.97it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.06it/s]\u001b[A\n","Epoch:  10% 10/100 [00:24<03:50,  2.56s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.95it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.08it/s]\u001b[A\n","Epoch:  11% 11/100 [00:27<03:41,  2.49s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.79it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.84it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.84it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.03it/s]\u001b[A\n","Epoch:  12% 12/100 [00:29<03:36,  2.46s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.81it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.79it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.78it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.87it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.83it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  13% 13/100 [00:31<03:32,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.92it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.95it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  14% 14/100 [00:34<03:27,  2.41s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A12/11/2019 00:03:27 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-100/config.json\n","12/11/2019 00:03:28 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-100/pytorch_model.bin\n","12/11/2019 00:03:28 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-100\n","\n","Iteration:  29% 2/7 [00:02<00:03,  1.36it/s]\u001b[A\n","Iteration:  43% 3/7 [00:02<00:02,  1.63it/s]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:01,  1.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:03<00:00,  2.06it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  2.27it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.57it/s]\u001b[A\n","Epoch:  15% 15/100 [00:37<03:56,  2.79s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.93it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.93it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.18it/s]\u001b[A\n","Epoch:  16% 16/100 [00:40<03:41,  2.64s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.01it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.96it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.97it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.17it/s]\u001b[A\n","Epoch:  17% 17/100 [00:42<03:30,  2.53s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.97it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.97it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  18% 18/100 [00:44<03:21,  2.46s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.97it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.97it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.15it/s]\u001b[A\n","Epoch:  19% 19/100 [00:47<03:15,  2.41s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.75it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.81it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.79it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.84it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.03it/s]\u001b[A\n","Epoch:  20% 20/100 [00:49<03:12,  2.40s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  21% 21/100 [00:51<03:08,  2.38s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.82it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.86it/s]\u001b[A12/11/2019 00:03:45 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-150/config.json\n","12/11/2019 00:03:46 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-150/pytorch_model.bin\n","12/11/2019 00:03:46 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-150\n","\n","Iteration:  43% 3/7 [00:02<00:02,  1.34it/s]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:01,  1.59it/s]\u001b[A\n","Iteration:  71% 5/7 [00:03<00:01,  1.82it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  2.04it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.33it/s]\u001b[A\n","Epoch:  22% 22/100 [00:55<03:37,  2.79s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.16it/s]\u001b[A\n","Epoch:  23% 23/100 [00:57<03:22,  2.64s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.97it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.08it/s]\u001b[A\n","Epoch:  24% 24/100 [01:00<03:13,  2.54s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.78it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.83it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.85it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Epoch:  25% 25/100 [01:02<03:07,  2.50s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.82it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.78it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  26% 26/100 [01:04<03:02,  2.47s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  27% 27/100 [01:07<02:57,  2.43s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.80it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.85it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.96it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.16it/s]\u001b[A\n","Epoch:  28% 28/100 [01:09<02:52,  2.39s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  3.00it/s]\u001b[A12/11/2019 00:04:03 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-200/config.json\n","12/11/2019 00:04:04 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-200/pytorch_model.bin\n","12/11/2019 00:04:04 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-200\n","\n","Iteration:  57% 4/7 [00:02<00:02,  1.38it/s]\u001b[A\n","Iteration:  71% 5/7 [00:02<00:01,  1.64it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.19it/s]\u001b[A\n","Epoch:  29% 29/100 [01:13<03:15,  2.76s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.95it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.96it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.12it/s]\u001b[A\n","Epoch:  30% 30/100 [01:15<03:03,  2.62s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  31% 31/100 [01:17<02:55,  2.54s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.12it/s]\u001b[A\n","Epoch:  32% 32/100 [01:20<02:47,  2.47s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.83it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.85it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.84it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.88it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.03it/s]\u001b[A\n","Epoch:  33% 33/100 [01:22<02:43,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.87it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  34% 34/100 [01:24<02:39,  2.42s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:  35% 35/100 [01:27<02:35,  2.39s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.97it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A12/11/2019 00:04:21 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-250/config.json\n","12/11/2019 00:04:22 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-250/pytorch_model.bin\n","12/11/2019 00:04:22 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-250\n","\n","Iteration:  71% 5/7 [00:02<00:01,  1.42it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.67it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.00it/s]\u001b[A\n","Epoch:  36% 36/100 [01:30<02:54,  2.73s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.81it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.82it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.84it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n","Epoch:  37% 37/100 [01:33<02:45,  2.63s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.84it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.88it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  38% 38/100 [01:35<02:37,  2.55s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  39% 39/100 [01:37<02:32,  2.49s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.89it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n","Epoch:  40% 40/100 [01:40<02:27,  2.47s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.87it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.89it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  41% 41/100 [01:42<02:23,  2.43s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.96it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.97it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.15it/s]\u001b[A\n","Epoch:  42% 42/100 [01:44<02:18,  2.39s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.97it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.96it/s]\u001b[A12/11/2019 00:04:39 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-300/config.json\n","12/11/2019 00:04:40 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-300/pytorch_model.bin\n","12/11/2019 00:04:40 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-300\n","\n","Iteration:  86% 6/7 [00:03<00:00,  1.42it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  1.73it/s]\u001b[A\n","Epoch:  43% 43/100 [01:48<02:35,  2.74s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.91it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n","Epoch:  44% 44/100 [01:50<02:27,  2.63s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.85it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.87it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  45% 45/100 [01:53<02:19,  2.54s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.93it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.88it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.08it/s]\u001b[A\n","Epoch:  46% 46/100 [01:55<02:14,  2.48s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.96it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.90it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.05it/s]\u001b[A\n","Epoch:  47% 47/100 [01:57<02:09,  2.45s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.71it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.72it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.79it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.77it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.82it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n","Epoch:  48% 48/100 [02:00<02:06,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.78it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.84it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.88it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  49% 49/100 [02:02<02:03,  2.41s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.99it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.98it/s]\u001b[A12/11/2019 00:04:57 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-350/config.json\n","12/11/2019 00:04:58 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-350/pytorch_model.bin\n","12/11/2019 00:04:58 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-350\n","\n","Iteration: 100% 7/7 [00:03<00:00,  1.45it/s]\u001b[A\n","Epoch:  50% 50/100 [02:06<02:17,  2.75s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.84it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.96it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:  51% 51/100 [02:08<02:08,  2.62s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.11it/s]\u001b[A\n","Epoch:  52% 52/100 [02:10<02:01,  2.53s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.01it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.85it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n","Epoch:  53% 53/100 [02:13<01:57,  2.49s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.97it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.89it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  54% 54/100 [02:15<01:52,  2.45s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.86it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.89it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  55% 55/100 [02:17<01:49,  2.43s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.83it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.86it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  56% 56/100 [02:20<01:45,  2.40s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.95it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  57% 57/100 [02:22<01:42,  2.38s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A12/11/2019 00:05:15 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-400/config.json\n","12/11/2019 00:05:16 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-400/pytorch_model.bin\n","12/11/2019 00:05:16 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-400\n","\n","Iteration:  14% 1/7 [00:01<00:08,  1.49s/it]\u001b[A\n","Iteration:  29% 2/7 [00:01<00:05,  1.14s/it]\u001b[A\n","Iteration:  43% 3/7 [00:02<00:03,  1.11it/s]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:02,  1.37it/s]\u001b[A\n","Iteration:  71% 5/7 [00:02<00:01,  1.62it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.20it/s]\u001b[A\n","Epoch:  58% 58/100 [02:26<01:53,  2.70s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  3.00it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  3.00it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.99it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  59% 59/100 [02:28<01:45,  2.58s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:  60% 60/100 [02:30<01:40,  2.50s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.83it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.84it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.81it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.79it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.97it/s]\u001b[A\n","Epoch:  61% 61/100 [02:33<01:36,  2.48s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.75it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.76it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.78it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.87it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.91it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.08it/s]\u001b[A\n","Epoch:  62% 62/100 [02:35<01:32,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.77it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.83it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.84it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.84it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  63% 63/100 [02:37<01:29,  2.42s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.11it/s]\u001b[A\n","Epoch:  64% 64/100 [02:40<01:25,  2.39s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A12/11/2019 00:05:33 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-450/config.json\n","12/11/2019 00:05:34 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-450/pytorch_model.bin\n","12/11/2019 00:05:34 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-450\n","\n","Iteration:  29% 2/7 [00:01<00:03,  1.43it/s]\u001b[A\n","Iteration:  43% 3/7 [00:02<00:02,  1.70it/s]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:01,  1.95it/s]\u001b[A\n","Iteration:  71% 5/7 [00:02<00:00,  2.15it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  2.32it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.61it/s]\u001b[A\n","Epoch:  65% 65/100 [02:43<01:35,  2.73s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.11it/s]\u001b[A\n","Epoch:  66% 66/100 [02:45<01:28,  2.61s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.02it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.98it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.99it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.97it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  67% 67/100 [02:48<01:23,  2.52s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.96it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.91it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.05it/s]\u001b[A\n","Epoch:  68% 68/100 [02:50<01:19,  2.47s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.84it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.79it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.80it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Epoch:  69% 69/100 [02:53<01:16,  2.46s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.88it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.80it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.80it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.79it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Epoch:  70% 70/100 [02:55<01:13,  2.45s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.93it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.95it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.87it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.89it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  71% 71/100 [02:57<01:10,  2.42s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A12/11/2019 00:05:51 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-500/config.json\n","12/11/2019 00:05:52 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-500/pytorch_model.bin\n","12/11/2019 00:05:52 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-500\n","\n","Iteration:  43% 3/7 [00:02<00:02,  1.37it/s]\u001b[A\n","Iteration:  57% 4/7 [00:02<00:01,  1.63it/s]\u001b[A\n","Iteration:  71% 5/7 [00:03<00:01,  1.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  2.12it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.42it/s]\u001b[A\n","Epoch:  72% 72/100 [03:01<01:17,  2.78s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.82it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.81it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:  73% 73/100 [03:03<01:11,  2.65s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.97it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.83it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  74% 74/100 [03:06<01:06,  2.57s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.72it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.77it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.85it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.85it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.80it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.94it/s]\u001b[A\n","Epoch:  75% 75/100 [03:08<01:03,  2.52s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.77it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.78it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.80it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.82it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.80it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Epoch:  76% 76/100 [03:11<00:59,  2.50s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.81it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.85it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.10it/s]\u001b[A\n","Epoch:  77% 77/100 [03:13<00:56,  2.45s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.12it/s]\u001b[A\n","Epoch:  78% 78/100 [03:15<00:53,  2.41s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:01,  3.01it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.97it/s]\u001b[A12/11/2019 00:06:09 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-550/config.json\n","12/11/2019 00:06:10 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-550/pytorch_model.bin\n","12/11/2019 00:06:10 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-550\n","\n","Iteration:  57% 4/7 [00:02<00:02,  1.45it/s]\u001b[A\n","Iteration:  71% 5/7 [00:02<00:01,  1.70it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.24it/s]\u001b[A\n","Epoch:  79% 79/100 [03:19<00:57,  2.74s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.95it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.96it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.91it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.10it/s]\u001b[A\n","Epoch:  80% 80/100 [03:21<00:52,  2.62s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  3.00it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  3.00it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.08it/s]\u001b[A\n","Epoch:  81% 81/100 [03:23<00:48,  2.53s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.83it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.83it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.84it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.84it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.88it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n","Epoch:  82% 82/100 [03:26<00:44,  2.49s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  3.00it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.99it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.88it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.05it/s]\u001b[A\n","Epoch:  83% 83/100 [03:28<00:41,  2.45s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.71it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.75it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.81it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  84% 84/100 [03:30<00:38,  2.42s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.79it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.82it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.83it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.87it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.05it/s]\u001b[A\n","Epoch:  85% 85/100 [03:33<00:36,  2.40s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.89it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.91it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A12/11/2019 00:06:27 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-600/config.json\n","12/11/2019 00:06:28 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-600/pytorch_model.bin\n","12/11/2019 00:06:28 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-600\n","\n","Iteration:  71% 5/7 [00:02<00:01,  1.42it/s]\u001b[A\n","Iteration:  86% 6/7 [00:03<00:00,  1.69it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  2.01it/s]\u001b[A\n","Epoch:  86% 86/100 [03:36<00:38,  2.74s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.97it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.91it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.94it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  87% 87/100 [03:39<00:33,  2.61s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.88it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.87it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  88% 88/100 [03:41<00:30,  2.54s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.83it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.83it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n","Epoch:  89% 89/100 [03:43<00:27,  2.50s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.72it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.76it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.82it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.86it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.89it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.85it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n","Epoch:  90% 90/100 [03:46<00:24,  2.46s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.94it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.84it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.81it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.86it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.07it/s]\u001b[A\n","Epoch:  91% 91/100 [03:48<00:21,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.89it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.95it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.96it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.14it/s]\u001b[A\n","Epoch:  92% 92/100 [03:50<00:19,  2.40s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.84it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A12/11/2019 00:06:45 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-650/config.json\n","12/11/2019 00:06:46 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-650/pytorch_model.bin\n","12/11/2019 00:06:46 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-650\n","\n","Iteration:  86% 6/7 [00:03<00:00,  1.40it/s]\u001b[A\n","Iteration: 100% 7/7 [00:03<00:00,  1.69it/s]\u001b[A\n","Epoch:  93% 93/100 [03:54<00:19,  2.76s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.94it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.93it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.89it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.92it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.94it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.95it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.13it/s]\u001b[A\n","Epoch:  94% 94/100 [03:56<00:15,  2.63s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.98it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.98it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.95it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.91it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.11it/s]\u001b[A\n","Epoch:  95% 95/100 [03:59<00:12,  2.54s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.95it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.97it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.94it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.93it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  96% 96/100 [04:01<00:09,  2.47s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.97it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.95it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.91it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.91it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.06it/s]\u001b[A\n","Epoch:  97% 97/100 [04:03<00:07,  2.44s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.99it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.96it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.90it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.92it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.90it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.04it/s]\u001b[A\n","Epoch:  98% 98/100 [04:06<00:04,  2.42s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.87it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.90it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.87it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.88it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.90it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.92it/s]\u001b[A\n","Iteration: 100% 7/7 [00:02<00:00,  3.09it/s]\u001b[A\n","Epoch:  99% 99/100 [04:08<00:02,  2.39s/it]\n","Iteration:   0% 0/7 [00:00<?, ?it/s]\u001b[A\n","Iteration:  14% 1/7 [00:00<00:02,  2.84it/s]\u001b[A\n","Iteration:  29% 2/7 [00:00<00:01,  2.88it/s]\u001b[A\n","Iteration:  43% 3/7 [00:01<00:01,  2.91it/s]\u001b[A\n","Iteration:  57% 4/7 [00:01<00:01,  2.93it/s]\u001b[A\n","Iteration:  71% 5/7 [00:01<00:00,  2.93it/s]\u001b[A\n","Iteration:  86% 6/7 [00:02<00:00,  2.94it/s]\u001b[A12/11/2019 00:07:03 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/checkpoint-700/config.json\n","12/11/2019 00:07:04 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/checkpoint-700/pytorch_model.bin\n","12/11/2019 00:07:04 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen/checkpoint-700\n","\n","Iteration: 100% 7/7 [00:03<00:00,  1.33it/s]\u001b[A\n","Epoch: 100% 100/100 [04:12<00:00,  2.80s/it]\n","12/11/2019 00:07:04 - INFO - __main__ -    global_step = 700, average loss = 3.1247986820765905\n","12/11/2019 00:07:04 - INFO - __main__ -   Saving model checkpoint to bert_base_qa_oxygen\n","12/11/2019 00:07:04 - INFO - transformers.configuration_utils -   Configuration saved in bert_base_qa_oxygen/config.json\n","12/11/2019 00:07:06 - INFO - transformers.modeling_utils -   Model weights saved in bert_base_qa_oxygen/pytorch_model.bin\n","12/11/2019 00:07:06 - INFO - transformers.configuration_utils -   loading configuration file bert_base_qa_oxygen/config.json\n","12/11/2019 00:07:06 - INFO - transformers.configuration_utils -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 28996\n","}\n","\n","12/11/2019 00:07:06 - INFO - transformers.modeling_utils -   loading weights file bert_base_qa_oxygen/pytorch_model.bin\n","12/11/2019 00:07:10 - INFO - transformers.tokenization_utils -   Model name 'bert_base_qa_oxygen' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'bert_base_qa_oxygen' is a path or url to a directory containing tokenizer files.\n","12/11/2019 00:07:10 - INFO - transformers.tokenization_utils -   loading file bert_base_qa_oxygen/vocab.txt\n","12/11/2019 00:07:10 - INFO - transformers.tokenization_utils -   loading file bert_base_qa_oxygen/added_tokens.json\n","12/11/2019 00:07:10 - INFO - transformers.tokenization_utils -   loading file bert_base_qa_oxygen/special_tokens_map.json\n","12/11/2019 00:07:10 - INFO - transformers.tokenization_utils -   loading file bert_base_qa_oxygen/tokenizer_config.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6eEoDOh8UYWc","colab_type":"code","outputId":"5c0bef8b-bb6b-448a-beba-d258d1900997","executionInfo":{"status":"ok","timestamp":1576010820692,"user_tz":300,"elapsed":3222,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":[""],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TOayuqqlSP7A","colab_type":"code","outputId":"f6d856b7-a546-4387-c95e-85fa1d3feb2f","executionInfo":{"status":"ok","timestamp":1576007195316,"user_tz":300,"elapsed":10593,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n","import os\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model.eval()\n","output_dir = \"bert_base_uncased\"\n","output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n","output_config_file = os.path.join(output_dir, CONFIG_NAME)\n","model_to_save = model.module if hasattr(model, 'module') else model\n","\n","# If we save using the predefined names, we can load using `from_pretrained`\n","output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n","output_config_file = os.path.join(output_dir, CONFIG_NAME)\n","\n","torch.save(model_to_save.state_dict(), output_model_file)\n","model_to_save.config.to_json_file(output_config_file)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","tokenizer.save_vocabulary(output_dir)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 429553.41B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'bert_base_uncased/vocab.txt'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"VI40tIuqVev1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Om7BDE3tWtUX","colab_type":"code","outputId":"59f5175b-5ebb-4551-94b3-8880b8ee7b08","executionInfo":{"status":"ok","timestamp":1576008780611,"user_tz":300,"elapsed":1148,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}},"colab":{"base_uri":"https://localhost:8080/","height":181}},"source":["text = \"As well as granting to protect the area of Rouen from Viking invasion, Rollo had to swear not to invade further Frankish lands himself,\\\n","  accept baptism and conversion to the Roman Catholic faith of Christianity becoming Christian and swear fealty to King Charles III.\"\n","model.eval()\n","# Add the special tokens.\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","# Split the sentence into tokens.\n","tokenized_text = tokenizer.tokenize(marked_text)\n","\n","# Map the token strings to their vocabulary indeces.\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","# Display the words with their indeces.\n","# for tup in zip(tokenized_text, indexed_tokens):\n","    # print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n","# Mark each of the 22 tokens as belonging to sentence \"1\".\n","segments_ids = [1] * len(tokenized_text)\n","\n","# print (segments_ids)\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n","# for i, token_str in enumerate(tokenized_text):\n","  # print (i, token_str)\n","\n","# create a new dimension in the tensor.\n","token_embeddings = torch.stack(encoded_layers, dim=0)\n","\n","token_embeddings.size()\n","# Remove dimension 1, the \"batches\".\n","token_embeddings = torch.squeeze(token_embeddings, dim=1)\n","\n","token_embeddings.size()\n","token_embeddings = token_embeddings.permute(1,0,2)\n","\n","token_embeddings.size()\n","token_vecs_sum = []\n","\n","# `token_embeddings` is a [22 x 12 x 768] tensor.\n","\n","# For each token in the sentence...\n","for token in token_embeddings:\n","\n","    # `token` is a [12 x 768] tensor\n","\n","    # Sum the vectors from the last four layers.\n","    sum_vec = torch.sum(token[-4:], dim=0)\n","    \n","    # Use `sum_vec` to represent `token`.\n","    token_vecs_sum.append(sum_vec)\n","\n","# print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))\n","# print('First 5 vector values for each instance of \"bank\".')\n","print('')\n","print(\"Christian  \", str(token_vecs_sum[40][:5]))\n","print(\"christianity  \", str(token_vecs_sum[38][:5]))\n","print(\"Invade  \", str(token_vecs_sum[6][:5]))\n","print(\"Invasion  \", str(token_vecs_sum[13][:5]))\n","print(\"Protect  \", str(token_vecs_sum[22][:5]))\n","from scipy.spatial.distance import cosine\n","\n","\n","# Calculate the cosine similarity between the word bank\n","# in \"bank robber\" vs \"bank vault\" (same meaning).\n","same_bank = 1 - cosine(token_vecs_sum[40], token_vecs_sum[38])\n","same_invade = 1 - cosine(token_vecs_sum[6], token_vecs_sum[13])\n","diff_bank = 1 - cosine(token_vecs_sum[6], token_vecs_sum[22])\n","\n","print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n","print('Vector similarity for  *similar*  meanings:  %.2f' % same_invade)\n","print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Christian   tensor([-1.6235, -0.4515,  4.2368, -2.8883,  4.6358])\n","christianity   tensor([-1.1168, -0.3897,  4.7106, -2.4909,  1.6166])\n","Invade   tensor([-1.8865, -0.2210,  0.2764, -0.5681, -2.1856])\n","Invasion   tensor([-2.3899,  1.0758, -0.2707, -0.9449,  2.7009])\n","Protect   tensor([-2.3600,  1.9446,  1.5708, -0.1653,  0.2539])\n","Vector similarity for  *similar*  meanings:  0.81\n","Vector similarity for  *similar*  meanings:  0.51\n","Vector similarity for *different* meanings:  0.59\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TcXugGFTiyZU","colab_type":"code","colab":{}},"source":["from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n","import os\n","# model = BertModel.from_pretrained('bert-base-uncased')\n","# model.eval()\n","output_dir = \"bert_base_uncased\"\n","# output_dir = \"bert_base_uncased\"\n","model = BertModel.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir, True)  # Add specific options if needed\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BV2xV2C8kHP0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":345},"outputId":"12ed4fc5-db62-41d3-8ada-3765ff4ff0a5","executionInfo":{"status":"ok","timestamp":1576011702357,"user_tz":300,"elapsed":1524,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}}},"source":["text = \"The silicates are an amazingly complex group of materials that typically consist of greater than 50 (atomic) percent oxygen in combination with silicon and one or more metallic elements.\"\n","text = \"Man and woman are not same as king and queen.\"\n","model.eval()\n","# Add the special tokens.\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","# Split the sentence into tokens.\n","tokenized_text = tokenizer.tokenize(marked_text)\n","\n","# Map the token strings to their vocabulary indeces.\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","# Display the words with their indeces.\n","# for tup in zip(tokenized_text, indexed_tokens):\n","    # print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n","# Mark each of the 22 tokens as belonging to sentence \"1\".\n","segments_ids = [1] * len(tokenized_text)\n","\n","# print (segments_ids)\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n","for i, token_str in enumerate(tokenized_text):\n","  print (i, token_str)\n","\n","# create a new dimension in the tensor.\n","token_embeddings = torch.stack(encoded_layers, dim=0)\n","\n","token_embeddings.size()\n","# Remove dimension 1, the \"batches\".\n","token_embeddings = torch.squeeze(token_embeddings, dim=1)\n","\n","token_embeddings.size()\n","token_embeddings = token_embeddings.permute(1,0,2)\n","\n","token_embeddings.size()\n","token_vecs_sum = []\n","\n","# `token_embeddings` is a [22 x 12 x 768] tensor.\n","\n","# For each token in the sentence...\n","for token in token_embeddings:\n","\n","    # `token` is a [12 x 768] tensor\n","\n","    # Sum the vectors from the last four layers.\n","    sum_vec = torch.sum(token[-4:], dim=0)\n","    \n","    # Use `sum_vec` to represent `token`.\n","    token_vecs_sum.append(sum_vec)\n","\n","# print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))\n","# print('First 5 vector values for each instance of \"bank\".')\n","print('')\n","# print(\"Christian  \", str(token_vecs_sum[40][:5]))\n","# print(\"christianity  \", str(token_vecs_sum[38][:5]))\n","# print(\"Invade  \", str(token_vecs_sum[6][:5]))\n","# print(\"Invasion  \", str(token_vecs_sum[13][:5]))\n","# print(\"Protect  \", str(token_vecs_sum[22][:5]))\n","from scipy.spatial.distance import cosine\n","\n","\n","# Calculate the cosine similarity between the word bank\n","# in \"bank robber\" vs \"bank vault\" (same meaning).\n","# same_bank = 1 - cosine(token_vecs_sum[17], token_vecs_sum[22])\n","# same_invade = 1 - cosine(token_vecs_sum[6], token_vecs_sum[13])\n","# diff_bank = 1 - cosine(token_vecs_sum[6], token_vecs_sum[22])\n","man =  1 -cosine(token_vecs_sum[1], token_vecs_sum[8])\n","woman =  1 -cosine(token_vecs_sum[3], token_vecs_sum[10])\n","king =  1 -cosine(token_vecs_sum[1], token_vecs_sum[3])\n","queen =  1 -cosine(token_vecs_sum[8], token_vecs_sum[10])\n","\n","# print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n","# print('Vector similarity for  *similar*  meanings:  %.2f' % same_invade)\n","# print('Vector similarity for *different* meanings:  %.2f' % diff_bank)\n","print('Vector similarity for  *similar*  meanings:  %.2f' % man)\n","print('Vector similarity for *different* meanings:  %.2f' % woman)\n","print('Vector similarity for  *similar*  meanings:  %.2f' % king)\n","print('Vector similarity for *different* meanings:  %.2f' % queen)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["0 [CLS]\n","1 man\n","2 and\n","3 woman\n","4 are\n","5 not\n","6 same\n","7 as\n","8 king\n","9 and\n","10 queen\n","11 .\n","12 [SEP]\n","\n","Vector similarity for  *similar*  meanings:  0.64\n","Vector similarity for *different* meanings:  0.69\n","Vector similarity for  *similar*  meanings:  0.76\n","Vector similarity for *different* meanings:  0.78\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Ed3ZlankRcw","colab_type":"code","colab":{}},"source":["model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuldLzA_moFE","colab_type":"code","colab":{}},"source":["from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n","import os\n","# model = BertModel.from_pretrained('bert-base-uncased')\n","# model.eval()\n","output_dir = \"bert_base_cased_qa\"\n","# output_dir = \"bert_base_uncased\"\n","model = BertModel.from_pretrained(output_dir)\n","model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnZagJKjTLuN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"66baf560-d441-4a47-f2cf-f1d2c4902004","executionInfo":{"status":"ok","timestamp":1576023149487,"user_tz":300,"elapsed":445,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}}},"source":[""],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"rKG6sT-LTMmI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cb9d050a-f076-4332-8cb6-e8899ea7c172","executionInfo":{"status":"ok","timestamp":1576023194334,"user_tz":300,"elapsed":2362,"user":{"displayName":"Abdullah Mitkar","photoUrl":"","userId":"17001243474945681698"}}},"source":["output_dir=\"bert_base_qa_oxygen\"\n","model = BertModel.from_pretrained(output_dir)\n","model"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"3oSrcWHRTXEQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}